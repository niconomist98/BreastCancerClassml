{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Trabajo Preparacion, visualizacion de Datos y Machine learning con Python<a class=\"tocSkip\">\n",
    "## Ciencia de datos en Produccion <a class=\"tocSkip\">\n",
    "\n",
    "**Estudiantes :** Francisco Ocampo y Nicolas Restrepo\n",
    "\n",
    "**ID:** 10953409583, 1094966547\n",
    "\n",
    "**Email:** nrestrepoc@uqvirtual.edu.co, fjocampog@uqvirtual.edu.co\n",
    "\n",
    "\n",
    "**Ponga su nombre en el archivo de Jupyter Notebook\n",
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Contenido<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Definir-el-Problema-a-Resolver\" data-toc-modified-id=\"Definir-el-Problema-a-Resolver-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Definir el Problema a Resolver</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describir-los-datos-de-entrada-y-salida\" data-toc-modified-id=\"Describir-los-datos-de-entrada-y-salida-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Describir los datos de entrada y salida</a></span></li></ul></li><li><span><a href=\"#Importar-Librerias\" data-toc-modified-id=\"Importar-Librerias-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importar Librerias</a></span></li><li><span><a href=\"#Cargar-Datasets\" data-toc-modified-id=\"Cargar-Datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cargar Datasets</a></span></li><li><span><a href=\"#Descripcion--y-Limpieza-de-los-datos\" data-toc-modified-id=\"Descripcion--y-Limpieza-de-los-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Descripcion  y Limpieza de los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identificacion-de-Variables\" data-toc-modified-id=\"Identificacion-de-Variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Identificacion de Variables</a></span></li><li><span><a href=\"#Analisis-General-Univariable-y-Bivariable\" data-toc-modified-id=\"Analisis-General-Univariable-y-Bivariable-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Analisis General Univariable y Bivariable</a></span></li><li><span><a href=\"#Eliminar-columnas-de-datos-Innecesarios\" data-toc-modified-id=\"Eliminar-columnas-de-datos-Innecesarios-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Eliminar columnas de datos Innecesarios</a></span></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Procesamiento-de-Datos-Faltantes\" data-toc-modified-id=\"Procesamiento-de-Datos-Faltantes-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Procesamiento de Datos Faltantes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Borrar-Filas\" data-toc-modified-id=\"Borrar-Filas-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Borrar Filas</a></span></li><li><span><a href=\"#Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)\" data-toc-modified-id=\"Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Reemplazar datos faltantes con la Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)</a></span></li></ul></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Analisis-Univariable\" data-toc-modified-id=\"Analisis-Univariable-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Analisis Univariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-Numericas\" data-toc-modified-id=\"Variables-Numericas-4.7.1\"><span class=\"toc-item-num\">4.7.1&nbsp;&nbsp;</span>Variables Numericas</a></span></li><li><span><a href=\"#Variables-Categoricas\" data-toc-modified-id=\"Variables-Categoricas-4.7.2\"><span class=\"toc-item-num\">4.7.2&nbsp;&nbsp;</span>Variables Categoricas</a></span></li></ul></li><li><span><a href=\"#Analisis-Bivariable\" data-toc-modified-id=\"Analisis-Bivariable-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Analisis Bivariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numericas-vs-Numericas\" data-toc-modified-id=\"Numericas-vs-Numericas-4.8.1\"><span class=\"toc-item-num\">4.8.1&nbsp;&nbsp;</span>Numericas vs Numericas</a></span></li><li><span><a href=\"#Categoricas-vs-Categoricas\" data-toc-modified-id=\"Categoricas-vs-Categoricas-4.8.2\"><span class=\"toc-item-num\">4.8.2&nbsp;&nbsp;</span>Categoricas vs Categoricas</a></span></li><li><span><a href=\"#Categoricas-vs-Numericas\" data-toc-modified-id=\"Categoricas-vs-Numericas-4.8.3\"><span class=\"toc-item-num\">4.8.3&nbsp;&nbsp;</span>Categoricas vs Numericas</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.9\"><span class=\"toc-item-num\">4.9&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.9.1\"><span class=\"toc-item-num\">4.9.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.9.2\"><span class=\"toc-item-num\">4.9.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.10\"><span class=\"toc-item-num\">4.10&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.10.1\"><span class=\"toc-item-num\">4.10.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.10.2\"><span class=\"toc-item-num\">4.10.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4.11\"><span class=\"toc-item-num\">4.11&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transformacion-de-Variables\" data-toc-modified-id=\"Transformacion-de-Variables-4.11.1\"><span class=\"toc-item-num\">4.11.1&nbsp;&nbsp;</span>Transformacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalizacion\" data-toc-modified-id=\"Normalizacion-4.11.1.1\"><span class=\"toc-item-num\">4.11.1.1&nbsp;&nbsp;</span>Normalizacion</a></span></li><li><span><a href=\"#Escalamiento\" data-toc-modified-id=\"Escalamiento-4.11.1.2\"><span class=\"toc-item-num\">4.11.1.2&nbsp;&nbsp;</span>Escalamiento</a></span></li><li><span><a href=\"#Logaritmica\" data-toc-modified-id=\"Logaritmica-4.11.1.3\"><span class=\"toc-item-num\">4.11.1.3&nbsp;&nbsp;</span>Logaritmica</a></span></li><li><span><a href=\"#raíz-cuadrada-/-cúbica\" data-toc-modified-id=\"raíz-cuadrada-/-cúbica-4.11.1.4\"><span class=\"toc-item-num\">4.11.1.4&nbsp;&nbsp;</span>raíz cuadrada / cúbica</a></span></li><li><span><a href=\"#Binning-,-Cambios-de-Numericas-a-Categoricas\" data-toc-modified-id=\"Binning-,-Cambios-de-Numericas-a-Categoricas-4.11.1.5\"><span class=\"toc-item-num\">4.11.1.5&nbsp;&nbsp;</span>Binning , Cambios de Numericas a Categoricas</a></span></li></ul></li></ul></li><li><span><a href=\"#Analisis-Univariable-y-Bivariable-Final\" data-toc-modified-id=\"Analisis-Univariable-y-Bivariable-Final-4.12\"><span class=\"toc-item-num\">4.12&nbsp;&nbsp;</span>Analisis Univariable y Bivariable Final</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creacion-de-Variables\" data-toc-modified-id=\"Creacion-de-Variables-4.12.1\"><span class=\"toc-item-num\">4.12.1&nbsp;&nbsp;</span>Creacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Crear-Variables-derivadas-de-Otras\" data-toc-modified-id=\"Crear-Variables-derivadas-de-Otras-4.12.1.1\"><span class=\"toc-item-num\">4.12.1.1&nbsp;&nbsp;</span>Crear Variables derivadas de Otras</a></span></li><li><span><a href=\"#Crear-Variables-de-Categorico-a-Numerico\" data-toc-modified-id=\"Crear-Variables-de-Categorico-a-Numerico-4.12.1.2\"><span class=\"toc-item-num\">4.12.1.2&nbsp;&nbsp;</span>Crear Variables de Categorico a Numerico</a></span></li></ul></li></ul></li><li><span><a href=\"#Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)\" data-toc-modified-id=\"Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)-4.13\"><span class=\"toc-item-num\">4.13&nbsp;&nbsp;</span>Reduccion de Dimensionalidad y Seleccion de Variables (PCA)</a></span></li><li><span><a href=\"#Balance-de-datos\" data-toc-modified-id=\"Balance-de-datos-4.14\"><span class=\"toc-item-num\">4.14&nbsp;&nbsp;</span>Balance de datos</a></span></li></ul></li><li><span><a href=\"#MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)\" data-toc-modified-id=\"MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dividir-el-dataset-en-Training-set-y-Test-set\" data-toc-modified-id=\"Dividir-el-dataset-en-Training-set-y-Test-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dividir el dataset en Training set y Test set</a></span></li></ul></li><li><span><a href=\"#Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)\" data-toc-modified-id=\"Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validacion y Evaluacion Cruzada (k-fold Cross Validation)</a></span></li><li><span><a href=\"#Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)\" data-toc-modified-id=\"Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Optimizacion de Hiper parametros (Hyper Parameter optimization)</a></span></li><li><span><a href=\"#Evaluacion-final-del-modelo-con-el-Test-set\" data-toc-modified-id=\"Evaluacion-final-del-modelo-con-el-Test-set-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluacion final del modelo con el Test set</a></span></li><li><span><a href=\"#Implementacion-del-Modelo-(Deploying)\" data-toc-modified-id=\"Implementacion-del-Modelo-(Deploying)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Implementacion del Modelo (Deploying)</a></span></li><li><span><a href=\"#Comunicacion-de-Resultados-(Data-Story-Telling)\" data-toc-modified-id=\"Comunicacion-de-Resultados-(Data-Story-Telling)-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Comunicacion de Resultados (Data Story Telling)</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Conclusiones</a></span></li><li><span><a href=\"#Ayudas-Y-Referencias\" data-toc-modified-id=\"Ayudas-Y-Referencias-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Ayudas Y Referencias</a></span></li></ul></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definición del problema a resolver\n",
    "El data set contiene las caracteristicas de una foto tomada mediante microscopio a un area celular bien definida de una biopsia a una masa mamaria.\n",
    "Las características se calculan a partir de una imagen digitalizada con aguja fina (PAAF) de la masa.\n",
    "Los datos describen  10 caracteristicas de cada muestra que dan cuenta del tamaño, forma y textura de los núcleos celulares presentes en la imagen.\n",
    "Se computan la media, error standard y  los valores extremos para cada una de las 10 caracteristicas de cada imagen estudiada resultando un total de 30 caracteristicas para cada muestra.\n",
    "El data set obtenido por el  Dr. Wolberg es conocido como  Wisconsin Breast Cancer Data y ha sido empleado para estudiar y clasificar correctamente casos de tumores malignos.\n",
    "La idea es utilizar el aprendizaje de maquina para determinar si la masa analizada es Benigna o Maligna. Para lograrlo se experimentara con distintos modelos de clasificacion para llegar a resultados que puedan contribuir a detectar casos de cancer.\n",
    "\n",
    "\n",
    "Para mas informacion sobre el procedimiento visitar :  https://pages.cs.wisc.edu/~olvi/uwmp/mpml.html\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Descripcion de los datos de entrada y salida\n",
    "\n",
    "| Feature name |Type|Missing %| Description and values\n",
    "|---|----------| --- | --- |--- |\n",
    "|diagnosis (Target) |Object  | 4.61%|Diagnosis : B (Benign) M (Malignant) for each case|\n",
    "| erty| int64 | 0%|...|\n",
    "| iuytr| Object | 4.18%|...|\n",
    "| idID number | int64 | 3.09% |unique identifier of the observation|\n",
    "| index | int64 | 0% |...|\n",
    "| radius_mean| Object | 3.60% |mean of distances from center to points on the perimeter|\n",
    "| texture_mean | Object | 3.83% |standard deviation of gray-scale values|\n",
    "| perimeter_mean | Object | 3.85% |mean size of the core tumor|\n",
    "| area_mean | Object | 4.46% |...|\n",
    "| smoothness_mean | Object | 4.49% |mean of local variation in radius lengths|\n",
    "| Compactness mean | Object | 3.93% |mean of perimeter^2 / area - 1.0|\n",
    "| Concavity mean| Object | 4.36% |mean of severity of concave portions of the contour|\n",
    "| concave points_mean | Object | 3.70% |mean for number of concave portions of the contour|\n",
    "| symmetry_mean | Object | 4.18% |...|\n",
    "| fractal_dimension_mean: | Object | 3.37% |mean for “coastline approximation” - 1|\n",
    "| radius_se | Object | 3.30% |standard error for the mean of distances from center to points on the perimeter|\n",
    "| texture_se| Object | 3.37%|standard error for standard deviation of gray-scale values|\n",
    "| perimeter_Se | Object | 3.52% |...|\n",
    "| area_se | Object | 4.13% |...|\n",
    "| smoothness_se| Object | 3.04% |standard error for local variation in radius lengths|\n",
    "| compactness_se | Object | 3.57% |standard error for perimeter^2 / area - 1.0|\n",
    "| concavity_se| Object | 4.08% |standard error for severity of concave portions of the contour|\n",
    "| concave points_se: | Object | 3.6% |standard error for number of concave portions of the contour|\n",
    "| symmetry_se | Object | 3.22% |...|\n",
    "| fractal_dimension_se | Object | 3.42% |standard error for “coastline approximation” - 1|\n",
    "| radius_worst | Object | 3.17% |“worst” or largest mean value for mean of distances from center to points on the perimeter|\n",
    "| texture_worst| Object | 3.29% |“worst” or largest mean value for standard deviation of gray-scale values|\n",
    "| perimeter_worst | Object | 3.23% |...|\n",
    "| area_worst | Object | 3.29% |...|\n",
    "| smoothness_worst | Object | 3.57% |“worst” or largest mean value for local variation in radius lengths|\n",
    "| compactness_worst| Object | 3.09% | “worst” or largest mean value for perimeter^2 / area - 1.0|\n",
    "| concavity_worst | Object | 3.32% |“worst” or largest mean value for severity of concave portions of the contour|\n",
    "| concave_points_worst | Object | 2.96%. |...|\n",
    "| simmetry_worst| Object | 3.17% |“worst” or largest mean value for severity of concave portions of the contour|\n",
    "| fractal_dimension_worst| Object | 3.12% | “worst” or largest mean value for “coastline approximation” - 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Checking the datatypes and values we can see the columns are not in the datatype they are supposed to, we need to change dtype Object for a numeric datatype in order to perform the analysis, we also see there are a few low values for each column. We'll solve these errors.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importar librerias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cargar Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/raw/BreastCancerDS.csv',index_col=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Descripcion general del dataset\n",
    "Raw datset contains 19710 rows and 35 columns, datatypes are not correct since  columns that are suppossed to be numeric are currently objects, we'll fix this problem later ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19710 entries, 0 to 19709\n",
      "Data columns (total 35 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   index                    19710 non-null  int64 \n",
      " 1   perimeter_se             19015 non-null  object\n",
      " 2   radius_worst             19085 non-null  object\n",
      " 3   concave points_mean      18980 non-null  object\n",
      " 4   smoothness_mean          18825 non-null  object\n",
      " 5   area_mean                18830 non-null  object\n",
      " 6   concavity_se             18905 non-null  object\n",
      " 7   texture_mean             18955 non-null  object\n",
      " 8   concavity_worst          19055 non-null  object\n",
      " 9   smoothness_se            19110 non-null  object\n",
      " 10  concave points_se        19000 non-null  object\n",
      " 11  area_worst               19060 non-null  object\n",
      " 12  compactness_mean         18935 non-null  object\n",
      " 13  radius_mean              19000 non-null  object\n",
      " 14  area_se                  18895 non-null  object\n",
      " 15  concave points_worst     19125 non-null  object\n",
      " 16  iuytr                    18885 non-null  object\n",
      " 17  fractal_dimension_worst  19095 non-null  object\n",
      " 18  perimeter_worst          19055 non-null  object\n",
      " 19  texture_se               19045 non-null  object\n",
      " 20  fractal_dimension_mean   19045 non-null  object\n",
      " 21  texture_worst            19060 non-null  object\n",
      " 22  smoothness_worst         19005 non-null  object\n",
      " 23  concavity_mean           18850 non-null  object\n",
      " 24  id                       19100 non-null  object\n",
      " 25  symmetry_mean            18885 non-null  object\n",
      " 26  symmetry_worst           19085 non-null  object\n",
      " 27  diagnosis                18800 non-null  object\n",
      " 28  erty                     19710 non-null  int64 \n",
      " 29  fractal_dimension_se     19035 non-null  object\n",
      " 30  perimeter_mean           18950 non-null  object\n",
      " 31  compactness_worst        19100 non-null  object\n",
      " 32  symmetry_se              19075 non-null  object\n",
      " 33  compactness_se           19005 non-null  object\n",
      " 34  radius_se                19060 non-null  object\n",
      "dtypes: int64(2), object(33)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Limpieza y calidad de datos general"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "index                        0\nperimeter_se               695\nradius_worst               625\nconcave points_mean        730\nsmoothness_mean            885\narea_mean                  880\nconcavity_se               805\ntexture_mean               755\nconcavity_worst            655\nsmoothness_se              600\nconcave points_se          710\narea_worst                 650\ncompactness_mean           775\nradius_mean                710\narea_se                    815\nconcave points_worst       585\niuytr                      825\nfractal_dimension_worst    615\nperimeter_worst            655\ntexture_se                 665\nfractal_dimension_mean     665\ntexture_worst              650\nsmoothness_worst           705\nconcavity_mean             860\nid                         610\nsymmetry_mean              825\nsymmetry_worst             625\ndiagnosis                  910\nerty                         0\nfractal_dimension_se       675\nperimeter_mean             760\ncompactness_worst          610\nsymmetry_se                635\ncompactness_se             705\nradius_se                  650\ndtype: int64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() ##checking amount of null data per column\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "       index               id\n0        223  999765432456788\n1        279          8911834\n2        307            89346\n3        571         857343.0\n4        576         85759902\n...      ...              ...\n19705    350           899187\n19706    442         90944601\n19707    279          8911834\n19708    501            91504\n19709    233         88206102\n\n[19710 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>223</td>\n      <td>999765432456788</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>279</td>\n      <td>8911834</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>307</td>\n      <td>89346</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>571</td>\n      <td>857343.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>576</td>\n      <td>85759902</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19705</th>\n      <td>350</td>\n      <td>899187</td>\n    </tr>\n    <tr>\n      <th>19706</th>\n      <td>442</td>\n      <td>90944601</td>\n    </tr>\n    <tr>\n      <th>19707</th>\n      <td>279</td>\n      <td>8911834</td>\n    </tr>\n    <tr>\n      <th>19708</th>\n      <td>501</td>\n      <td>91504</td>\n    </tr>\n    <tr>\n      <th>19709</th>\n      <td>233</td>\n      <td>88206102</td>\n    </tr>\n  </tbody>\n</table>\n<p>19710 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['index','id']] #checking differences between index and id\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking null values in index and id columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index null count : 0 , id null count: 610\n"
     ]
    }
   ],
   "source": [
    "print(\"index null count : \"+str(df[\"index\"].isnull().sum()), \", id null count: \"+ str(df[\"id\"].isnull().sum()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking duplicated rows we can see there are 15773 duplicated rows, it's necessary to fix it because since we are working on a dataset containing characteristics of different cases of breast mass cells, there is no reason for a case to be twice on the same dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "True     15773\nFalse     3937\ndtype: int64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts() ##checking duplicates\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking  our target (diagnosis) values, we see there are some values that do not make sense since are not labeled as B or M which are the only cases allowed in this dataset, then we need to fix this issue in order to keep just correctly labeled examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "B                          10245\nM                           5935\nNaN                          910\n999765432456788              655\n-88888765432345              655\n?                            655\nrxctf378968 7656463sdfg      655\nName: diagnosis, dtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts(dropna=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Cleaning target feature, we'll only use examples wich target is correctly labeled, in this case B ( benign) or M (Malignant)\n",
    "Before target cleaning we had 19710 entries, once the target is cleaned, we have 16180 entries.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "df=df[(df['diagnosis']=='B')|(df['diagnosis']=='M')] ## only correctly labeled examples are kept for the analysis.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "B    10245\nM     5935\nName: diagnosis, dtype: int64"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts() #now we only have B or M diagnosis in our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deleting iuytr y erty columns\n",
    "* 'Erty' Column contains the same value for each row, we can delete it since it provides no information.\n",
    "* 'iuytr' column contains the same information in 'symmetry_mean' we delete one of them, in this case 'iuytr' is deleted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "908765434567    16180\nName: erty, dtype: int64"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['erty'].value_counts() ## todos los valores son iguales, se borra erty\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df.drop('erty',axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "                         iuytr            symmetry_mean\n1                        211.0                    211.0\n2            -88888765432345.0        -88888765432345.0\n4                           ?                        ? \n5                       0.1671                   0.1671\n7                       0.1667                   0.1667\n...                        ...                      ...\n19703                    216.0                    216.0\n19705                   0.1671                   0.1671\n19706                   0.1405                   0.1405\n19708                   0.2275                   0.2275\n19709  rxctf378968 7656463sdfg  rxctf378968 7656463sdfg\n\n[16180 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>iuytr</th>\n      <th>symmetry_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>211.0</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-88888765432345.0</td>\n      <td>-88888765432345.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.1671</td>\n      <td>0.1671</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.1667</td>\n      <td>0.1667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19703</th>\n      <td>216.0</td>\n      <td>216.0</td>\n    </tr>\n    <tr>\n      <th>19705</th>\n      <td>0.1671</td>\n      <td>0.1671</td>\n    </tr>\n    <tr>\n      <th>19706</th>\n      <td>0.1405</td>\n      <td>0.1405</td>\n    </tr>\n    <tr>\n      <th>19708</th>\n      <td>0.2275</td>\n      <td>0.2275</td>\n    </tr>\n    <tr>\n      <th>19709</th>\n      <td>rxctf378968 7656463sdfg</td>\n      <td>rxctf378968 7656463sdfg</td>\n    </tr>\n  </tbody>\n</table>\n<p>16180 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['iuytr','symmetry_mean']] ## estas dos columnas tienen la misma informacion, borrar una\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df.drop('iuytr',axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "       index perimeter_se             radius_worst concave points_mean  \\\n1        279         1.83        999765432456788.0             0.03711   \n2        307       1144.0                   9699.0            0.003472   \n4        576       2183.0                       ?              0.02278   \n5        350       2225.0                    13.28             0.01162   \n7        120       1103.0                    12.82             0.02623   \n...      ...          ...                      ...                 ...   \n19703    602       2844.0                       ?              0.05613   \n19705    350       2225.0  rxctf378968 7656463sdfg             0.01162   \n19706    442       2235.0                    15.27            0.009937   \n19708    501       2974.0                    16.01             0.06759   \n19709    233       3767.0                    24.47              0.0834   \n\n         smoothness_mean area_mean concavity_se texture_mean concavity_worst  \\\n1                0.09516     587.4      0.01457        15.18          0.1456   \n2      -88888765432345.0     246.3     0.003681         14.4         0.01472   \n4                0.09524     409.0      0.01349        18.75              ?    \n5                0.07561     421.0     0.005949        17.07         0.03046   \n7                0.09373     403.3      0.01514        10.82          0.2102   \n...                  ...       ...          ...          ...             ...   \n19703             0.1008     809.8      0.02219        21.54          0.2992   \n19705            0.07561     421.0     0.005949        17.07         0.03046   \n19706  -88888765432345.0     585.9     0.007741        15.79         0.03517   \n19708             0.1162     595.9      0.03476        24.49          0.3381   \n19709            0.09159    1319.0      0.03457        27.81          0.4146   \n\n                 smoothness_se  ...        id            symmetry_mean  \\\n1                     0.004235  ...   8911834                    211.0   \n2                     0.007389  ...     89346        -88888765432345.0   \n4                     0.008328  ...  85759902                       ?    \n5                     0.006583  ...    899187                   0.1671   \n7                           ?   ...    865137                   0.1667   \n...                        ...  ...       ...                      ...   \n19703                 0.004877  ...  86730502                    216.0   \n19705  rxctf378968 7656463sdfg  ...    899187                   0.1671   \n19706        -88888765432345.0  ...  90944601                   0.1405   \n19708                  0.00968  ...     91504                   0.2275   \n19709                  0.00502  ...  88206102  rxctf378968 7656463sdfg   \n\n      symmetry_worst diagnosis     fractal_dimension_se     perimeter_mean  \\\n1             0.2955         B                 0.001593  999765432456788.0   \n2             0.2991         B                 0.002153              56.36   \n4             0.3306         B                 0.002386              73.34   \n5             0.2731         B                 0.002668               73.7   \n7             0.3016         B                 0.002206              73.34   \n...              ...       ...                      ...                ...   \n19703             ?          M                       ?               106.2   \n19705         0.2731         B  rxctf378968 7656463sdfg               73.7   \n19706         0.1859         B                 0.002564  -88888765432345.0   \n19708         0.3651         M                 0.006995              92.33   \n19709         0.2437         M                 0.002887              134.4   \n\n             compactness_worst        symmetry_se compactness_se  \\\n1                       0.1724            0.01528        0.01541   \n2                      0.05232            0.02701       0.004883   \n4                           ?             0.03218       0.008722   \n5                      0.06476            0.02216       0.006991   \n7                        239.0            0.01344             ?    \n...                        ...                ...            ...   \n19703                   0.3055            0.01535        0.01952   \n19705                  0.06476            0.02216       0.006991   \n19706                   0.1071  -88888765432345.0        0.01156   \n19708                   0.3966            0.02434        0.03856   \n19709  rxctf378968 7656463sdfg            0.01298        0.02062   \n\n               radius_se  \n1      999765432456788.0  \n2                 0.1746  \n4                 0.3249  \n5                 0.3534  \n7                     ?   \n...                  ...  \n19703             0.4332  \n19705             0.3534  \n19706             0.3563  \n19708             0.4751  \n19709              524.0  \n\n[16180 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>perimeter_se</th>\n      <th>radius_worst</th>\n      <th>concave points_mean</th>\n      <th>smoothness_mean</th>\n      <th>area_mean</th>\n      <th>concavity_se</th>\n      <th>texture_mean</th>\n      <th>concavity_worst</th>\n      <th>smoothness_se</th>\n      <th>...</th>\n      <th>id</th>\n      <th>symmetry_mean</th>\n      <th>symmetry_worst</th>\n      <th>diagnosis</th>\n      <th>fractal_dimension_se</th>\n      <th>perimeter_mean</th>\n      <th>compactness_worst</th>\n      <th>symmetry_se</th>\n      <th>compactness_se</th>\n      <th>radius_se</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>279</td>\n      <td>1.83</td>\n      <td>999765432456788.0</td>\n      <td>0.03711</td>\n      <td>0.09516</td>\n      <td>587.4</td>\n      <td>0.01457</td>\n      <td>15.18</td>\n      <td>0.1456</td>\n      <td>0.004235</td>\n      <td>...</td>\n      <td>8911834</td>\n      <td>211.0</td>\n      <td>0.2955</td>\n      <td>B</td>\n      <td>0.001593</td>\n      <td>999765432456788.0</td>\n      <td>0.1724</td>\n      <td>0.01528</td>\n      <td>0.01541</td>\n      <td>999765432456788.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>307</td>\n      <td>1144.0</td>\n      <td>9699.0</td>\n      <td>0.003472</td>\n      <td>-88888765432345.0</td>\n      <td>246.3</td>\n      <td>0.003681</td>\n      <td>14.4</td>\n      <td>0.01472</td>\n      <td>0.007389</td>\n      <td>...</td>\n      <td>89346</td>\n      <td>-88888765432345.0</td>\n      <td>0.2991</td>\n      <td>B</td>\n      <td>0.002153</td>\n      <td>56.36</td>\n      <td>0.05232</td>\n      <td>0.02701</td>\n      <td>0.004883</td>\n      <td>0.1746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>576</td>\n      <td>2183.0</td>\n      <td>?</td>\n      <td>0.02278</td>\n      <td>0.09524</td>\n      <td>409.0</td>\n      <td>0.01349</td>\n      <td>18.75</td>\n      <td>?</td>\n      <td>0.008328</td>\n      <td>...</td>\n      <td>85759902</td>\n      <td>?</td>\n      <td>0.3306</td>\n      <td>B</td>\n      <td>0.002386</td>\n      <td>73.34</td>\n      <td>?</td>\n      <td>0.03218</td>\n      <td>0.008722</td>\n      <td>0.3249</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>350</td>\n      <td>2225.0</td>\n      <td>13.28</td>\n      <td>0.01162</td>\n      <td>0.07561</td>\n      <td>421.0</td>\n      <td>0.005949</td>\n      <td>17.07</td>\n      <td>0.03046</td>\n      <td>0.006583</td>\n      <td>...</td>\n      <td>899187</td>\n      <td>0.1671</td>\n      <td>0.2731</td>\n      <td>B</td>\n      <td>0.002668</td>\n      <td>73.7</td>\n      <td>0.06476</td>\n      <td>0.02216</td>\n      <td>0.006991</td>\n      <td>0.3534</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>120</td>\n      <td>1103.0</td>\n      <td>12.82</td>\n      <td>0.02623</td>\n      <td>0.09373</td>\n      <td>403.3</td>\n      <td>0.01514</td>\n      <td>10.82</td>\n      <td>0.2102</td>\n      <td>?</td>\n      <td>...</td>\n      <td>865137</td>\n      <td>0.1667</td>\n      <td>0.3016</td>\n      <td>B</td>\n      <td>0.002206</td>\n      <td>73.34</td>\n      <td>239.0</td>\n      <td>0.01344</td>\n      <td>?</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19703</th>\n      <td>602</td>\n      <td>2844.0</td>\n      <td>?</td>\n      <td>0.05613</td>\n      <td>0.1008</td>\n      <td>809.8</td>\n      <td>0.02219</td>\n      <td>21.54</td>\n      <td>0.2992</td>\n      <td>0.004877</td>\n      <td>...</td>\n      <td>86730502</td>\n      <td>216.0</td>\n      <td>?</td>\n      <td>M</td>\n      <td>?</td>\n      <td>106.2</td>\n      <td>0.3055</td>\n      <td>0.01535</td>\n      <td>0.01952</td>\n      <td>0.4332</td>\n    </tr>\n    <tr>\n      <th>19705</th>\n      <td>350</td>\n      <td>2225.0</td>\n      <td>rxctf378968 7656463sdfg</td>\n      <td>0.01162</td>\n      <td>0.07561</td>\n      <td>421.0</td>\n      <td>0.005949</td>\n      <td>17.07</td>\n      <td>0.03046</td>\n      <td>rxctf378968 7656463sdfg</td>\n      <td>...</td>\n      <td>899187</td>\n      <td>0.1671</td>\n      <td>0.2731</td>\n      <td>B</td>\n      <td>rxctf378968 7656463sdfg</td>\n      <td>73.7</td>\n      <td>0.06476</td>\n      <td>0.02216</td>\n      <td>0.006991</td>\n      <td>0.3534</td>\n    </tr>\n    <tr>\n      <th>19706</th>\n      <td>442</td>\n      <td>2235.0</td>\n      <td>15.27</td>\n      <td>0.009937</td>\n      <td>-88888765432345.0</td>\n      <td>585.9</td>\n      <td>0.007741</td>\n      <td>15.79</td>\n      <td>0.03517</td>\n      <td>-88888765432345.0</td>\n      <td>...</td>\n      <td>90944601</td>\n      <td>0.1405</td>\n      <td>0.1859</td>\n      <td>B</td>\n      <td>0.002564</td>\n      <td>-88888765432345.0</td>\n      <td>0.1071</td>\n      <td>-88888765432345.0</td>\n      <td>0.01156</td>\n      <td>0.3563</td>\n    </tr>\n    <tr>\n      <th>19708</th>\n      <td>501</td>\n      <td>2974.0</td>\n      <td>16.01</td>\n      <td>0.06759</td>\n      <td>0.1162</td>\n      <td>595.9</td>\n      <td>0.03476</td>\n      <td>24.49</td>\n      <td>0.3381</td>\n      <td>0.00968</td>\n      <td>...</td>\n      <td>91504</td>\n      <td>0.2275</td>\n      <td>0.3651</td>\n      <td>M</td>\n      <td>0.006995</td>\n      <td>92.33</td>\n      <td>0.3966</td>\n      <td>0.02434</td>\n      <td>0.03856</td>\n      <td>0.4751</td>\n    </tr>\n    <tr>\n      <th>19709</th>\n      <td>233</td>\n      <td>3767.0</td>\n      <td>24.47</td>\n      <td>0.0834</td>\n      <td>0.09159</td>\n      <td>1319.0</td>\n      <td>0.03457</td>\n      <td>27.81</td>\n      <td>0.4146</td>\n      <td>0.00502</td>\n      <td>...</td>\n      <td>88206102</td>\n      <td>rxctf378968 7656463sdfg</td>\n      <td>0.2437</td>\n      <td>M</td>\n      <td>0.002887</td>\n      <td>134.4</td>\n      <td>rxctf378968 7656463sdfg</td>\n      <td>0.01298</td>\n      <td>0.02062</td>\n      <td>524.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>16180 rows × 33 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identifying missing values\n",
    "We found around 3-4% of na values for each feature, we'll analize what to do with these features after a more in depth analisis. See below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "perimeter_se               3.275649\nradius_worst               3.182942\nconcave points_mean        3.244747\nsmoothness_mean            4.295426\narea_mean                  4.140915\nconcavity_se               3.831891\ntexture_mean               3.522868\nconcavity_worst            3.213844\nsmoothness_se              2.626700\nconcave points_se          3.430161\narea_worst                 3.337454\ncompactness_mean           3.770087\nradius_mean                3.491965\narea_se                    3.831891\nconcave points_worst       2.997528\nfractal_dimension_worst    2.904821\nperimeter_worst            3.152040\ntexture_se                 3.182942\nfractal_dimension_mean     3.090235\ntexture_worst              3.244747\nsmoothness_worst           3.337454\nconcavity_mean             4.295426\nid                         2.657602\nsymmetry_mean              3.831891\nsymmetry_worst             2.843016\nfractal_dimension_se       3.059333\nperimeter_mean             3.770087\ncompactness_worst          2.966625\nsymmetry_se                2.966625\ncompactness_se             3.244747\nradius_se                  3.152040\ndtype: float64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing[missing>0]*100/len(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning blankspaces after and before data\n",
    "* At this point we need to check if our data has spaces at the beggining or at the end that we cannot see, in order to do this, we change index type to string and use a for cicle to apply str.strip() function to all the columns, so the spaces after and before each string are deleted. We'll change datatypes to numeric again as they are supossed to be,but this allows us to handle possible mistakes when cleaning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df['index']=df['index'].astype('string')\n",
    "list= ['index', 'perimeter_se', 'radius_worst', 'concave points_mean',\n",
    "       'smoothness_mean', 'area_mean', 'concavity_se', 'texture_mean',\n",
    "       'concavity_worst', 'smoothness_se', 'concave points_se', 'area_worst',\n",
    "       'compactness_mean', 'radius_mean', 'area_se', 'concave points_worst'\n",
    "       , 'fractal_dimension_worst', 'perimeter_worst', 'texture_se',\n",
    "       'fractal_dimension_mean', 'texture_worst', 'smoothness_worst',\n",
    "       'concavity_mean', 'id', 'symmetry_mean', 'symmetry_worst', 'diagnosis',\n",
    "       'fractal_dimension_se', 'perimeter_mean', 'compactness_worst',\n",
    "       'symmetry_se', 'compactness_se', 'radius_se']\n",
    "for i in list:\n",
    "    df[i]= df[i].str.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handling corrupt values\n",
    "* Checking the whole dataset, we can see there are 4 types of errors present in many (almost all) columns, we create a list with these errors and use a for cycle to replace these errors for np.nan in each column of our dataset (df) in order to better handle possible mistakes using methods for np.nan.\n",
    "\n",
    "\n",
    " Errors found:\n",
    "- 'rxctf378968 7656463sdfg'\n",
    "- '-88888765432345.0'\n",
    "- '999765432456788.0'\n",
    "- '?'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " **Checking the columns  one by one to find error types present in each column (only 6 value counts for each row are shown for presentation and understanding purposes).** Now we can confirm that the 4 error types  mentioned above are present in almost all columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122    30\n",
      "238    30\n",
      "149    30\n",
      "618    30\n",
      "628    30\n",
      "153    30\n",
      "Name: index, dtype: Int64\n",
      "\n",
      "------------------------\n",
      "rxctf378968 7656463sdfg    545\n",
      "-88888765432345.0          525\n",
      "?                          475\n",
      "999765432456788.0          465\n",
      "1778.0                      85\n",
      "2765.0                      80\n",
      "Name: perimeter_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          520\n",
      "999765432456788.0          515\n",
      "rxctf378968 7656463sdfg    510\n",
      "?                          490\n",
      "13.34                      115\n",
      "14.34                      115\n",
      "Name: radius_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          535\n",
      "rxctf378968 7656463sdfg    535\n",
      "999765432456788.0          500\n",
      "?                          485\n",
      "0.0                        300\n",
      "0.05564                     80\n",
      "Name: concave points_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "rxctf378968 7656463sdfg    555\n",
      "999765432456788.0          505\n",
      "?                          500\n",
      "-88888765432345.0          475\n",
      "0.1007                     120\n",
      "0.09462                    105\n",
      "Name: smoothness_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          555\n",
      "?                          540\n",
      "rxctf378968 7656463sdfg    510\n",
      "999765432456788.0          480\n",
      "520.2                       80\n",
      "686.9                       70\n",
      "Name: area_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "rxctf378968 7656463sdfg    555\n",
      "999765432456788.0          540\n",
      "-88888765432345.0          525\n",
      "?                          465\n",
      "0.0                        265\n",
      "0.0231                      80\n",
      "Name: concavity_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          535\n",
      "rxctf378968 7656463sdfg    530\n",
      "999765432456788.0          505\n",
      "-88888765432345.0          475\n",
      "14.93                       95\n",
      "18.18                       90\n",
      "Name: texture_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          560\n",
      "-88888765432345.0          530\n",
      "rxctf378968 7656463sdfg    525\n",
      "?                          505\n",
      "0.0                        285\n",
      "256.0                       80\n",
      "Name: concavity_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          545\n",
      "rxctf378968 7656463sdfg    535\n",
      "999765432456788.0          535\n",
      "-88888765432345.0          530\n",
      "0.006054                    75\n",
      "0.006766                    75\n",
      "Name: smoothness_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          520\n",
      "rxctf378968 7656463sdfg    510\n",
      "?                          505\n",
      "-88888765432345.0          490\n",
      "0.0                        280\n",
      "0.01499                    100\n",
      "Name: concave points_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          545\n",
      "?                          530\n",
      "999765432456788.0          520\n",
      "rxctf378968 7656463sdfg    515\n",
      "1437.0                     100\n",
      "830.5                       90\n",
      "Name: area_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          545\n",
      "999765432456788.0          540\n",
      "?                          515\n",
      "rxctf378968 7656463sdfg    490\n",
      "0.1483                      90\n",
      "0.05073                     70\n",
      "Name: compactness_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          540\n",
      "999765432456788.0          535\n",
      "?                          530\n",
      "rxctf378968 7656463sdfg    515\n",
      "13.0                       125\n",
      "11.6                        95\n",
      "Name: radius_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          540\n",
      "?                          535\n",
      "-88888765432345.0          525\n",
      "rxctf378968 7656463sdfg    485\n",
      "104.9                       85\n",
      "21.19                       70\n",
      "Name: area_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "rxctf378968 7656463sdfg    565\n",
      "999765432456788.0          515\n",
      "?                          510\n",
      "-88888765432345.0          485\n",
      "0.0                        295\n",
      "0.06296                     95\n",
      "Name: concave points_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          545\n",
      "?                          520\n",
      "rxctf378968 7656463sdfg    515\n",
      "999765432456788.0          515\n",
      "0.08273                     80\n",
      "0.08009                     75\n",
      "Name: fractal_dimension_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          540\n",
      "-88888765432345.0          515\n",
      "rxctf378968 7656463sdfg    515\n",
      "?                          505\n",
      "105.9                      100\n",
      "112.0                      100\n",
      "Name: perimeter_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          530\n",
      "?                          505\n",
      "-88888765432345.0          500\n",
      "rxctf378968 7656463sdfg    495\n",
      "1.15                       105\n",
      "1.35                       100\n",
      "Name: texture_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          535\n",
      "-88888765432345.0          535\n",
      "rxctf378968 7656463sdfg    535\n",
      "999765432456788.0          525\n",
      "0.06113                    115\n",
      "0.05913                    110\n",
      "Name: fractal_dimension_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          565\n",
      "-88888765432345.0          505\n",
      "?                          500\n",
      "rxctf378968 7656463sdfg    470\n",
      "19.35                      135\n",
      "27.26                       90\n",
      "Name: texture_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          545\n",
      "999765432456788.0          530\n",
      "rxctf378968 7656463sdfg    520\n",
      "-88888765432345.0          510\n",
      "0.1401                     120\n",
      "0.1368                     105\n",
      "Name: smoothness_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "rxctf378968 7656463sdfg    550\n",
      "?                          530\n",
      "-88888765432345.0          500\n",
      "999765432456788.0          490\n",
      "0.0                        265\n",
      "0.2133                      80\n",
      "Name: concavity_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          535\n",
      "-88888765432345            530\n",
      "999765432456788            500\n",
      "rxctf378968 7656463sdfg    495\n",
      "911366                      65\n",
      "911384                      60\n",
      "Name: id, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          550\n",
      "-88888765432345.0          520\n",
      "rxctf378968 7656463sdfg    515\n",
      "999765432456788.0          490\n",
      "0.1667                     130\n",
      "0.1893                     110\n",
      "Name: symmetry_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "-88888765432345.0          560\n",
      "999765432456788.0          535\n",
      "?                          530\n",
      "rxctf378968 7656463sdfg    495\n",
      "0.2972                     105\n",
      "0.2688                     100\n",
      "Name: symmetry_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "B    10245\n",
      "M     5935\n",
      "Name: diagnosis, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          560\n",
      "-88888765432345.0          530\n",
      "999765432456788.0          525\n",
      "rxctf378968 7656463sdfg    515\n",
      "0.001892                    80\n",
      "0.002379                    65\n",
      "Name: fractal_dimension_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          560\n",
      "-88888765432345.0          530\n",
      "rxctf378968 7656463sdfg    525\n",
      "?                          505\n",
      "82.61                      110\n",
      "87.76                      110\n",
      "Name: perimeter_mean, dtype: int64\n",
      "\n",
      "------------------------\n",
      "999765432456788.0          520\n",
      "-88888765432345.0          505\n",
      "rxctf378968 7656463sdfg    500\n",
      "?                          450\n",
      "0.4061                      85\n",
      "0.09726                     80\n",
      "Name: compactness_worst, dtype: int64\n",
      "\n",
      "------------------------\n",
      "rxctf378968 7656463sdfg    555\n",
      "-88888765432345.0          530\n",
      "999765432456788.0          525\n",
      "?                          510\n",
      "0.02045                    100\n",
      "0.01344                    100\n",
      "Name: symmetry_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          545\n",
      "999765432456788.0          530\n",
      "rxctf378968 7656463sdfg    530\n",
      "-88888765432345.0          480\n",
      "0.07025                     75\n",
      "0.008974                    70\n",
      "Name: compactness_se, dtype: int64\n",
      "\n",
      "------------------------\n",
      "?                          530\n",
      "rxctf378968 7656463sdfg    530\n",
      "999765432456788.0          520\n",
      "-88888765432345.0          495\n",
      "0.2621                     110\n",
      "0.2204                      95\n",
      "Name: radius_se, dtype: int64\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(df[i].value_counts().head(6))\n",
    "    print('\\n'+'------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a list with the 4 error types found and replacing those errors with na over the whole dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "list=['rxctf378968 7656463sdfg','-88888765432345.0','999765432456788.0','?']\n",
    "for i in list:\n",
    "       df.replace(i,np.nan,inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "      index perimeter_se radius_worst concave points_mean smoothness_mean  \\\n1       279         1.83          NaN             0.03711         0.09516   \n2       307       1144.0       9699.0            0.003472             NaN   \n4       576       2183.0          NaN             0.02278         0.09524   \n5       350       2225.0        13.28             0.01162         0.07561   \n7       120       1103.0        12.82             0.02623         0.09373   \n...     ...          ...          ...                 ...             ...   \n19703   602       2844.0          NaN             0.05613          0.1008   \n19705   350       2225.0          NaN             0.01162         0.07561   \n19706   442       2235.0        15.27            0.009937             NaN   \n19708   501       2974.0        16.01             0.06759          0.1162   \n19709   233       3767.0        24.47              0.0834         0.09159   \n\n      area_mean concavity_se texture_mean concavity_worst smoothness_se  ...  \\\n1         587.4      0.01457        15.18          0.1456      0.004235  ...   \n2         246.3     0.003681         14.4         0.01472      0.007389  ...   \n4         409.0      0.01349        18.75             NaN      0.008328  ...   \n5         421.0     0.005949        17.07         0.03046      0.006583  ...   \n7         403.3      0.01514        10.82          0.2102           NaN  ...   \n...         ...          ...          ...             ...           ...  ...   \n19703     809.8      0.02219        21.54          0.2992      0.004877  ...   \n19705     421.0     0.005949        17.07         0.03046           NaN  ...   \n19706     585.9     0.007741        15.79         0.03517           NaN  ...   \n19708     595.9      0.03476        24.49          0.3381       0.00968  ...   \n19709    1319.0      0.03457        27.81          0.4146       0.00502  ...   \n\n             id symmetry_mean symmetry_worst diagnosis fractal_dimension_se  \\\n1       8911834         211.0         0.2955         B             0.001593   \n2         89346           NaN         0.2991         B             0.002153   \n4      85759902           NaN         0.3306         B             0.002386   \n5        899187        0.1671         0.2731         B             0.002668   \n7        865137        0.1667         0.3016         B             0.002206   \n...         ...           ...            ...       ...                  ...   \n19703  86730502         216.0            NaN         M                  NaN   \n19705    899187        0.1671         0.2731         B                  NaN   \n19706  90944601        0.1405         0.1859         B             0.002564   \n19708     91504        0.2275         0.3651         M             0.006995   \n19709  88206102           NaN         0.2437         M             0.002887   \n\n      perimeter_mean compactness_worst symmetry_se compactness_se radius_se  \n1                NaN            0.1724     0.01528        0.01541       NaN  \n2              56.36           0.05232     0.02701       0.004883    0.1746  \n4              73.34               NaN     0.03218       0.008722    0.3249  \n5               73.7           0.06476     0.02216       0.006991    0.3534  \n7              73.34             239.0     0.01344            NaN       NaN  \n...              ...               ...         ...            ...       ...  \n19703          106.2            0.3055     0.01535        0.01952    0.4332  \n19705           73.7           0.06476     0.02216       0.006991    0.3534  \n19706            NaN            0.1071         NaN        0.01156    0.3563  \n19708          92.33            0.3966     0.02434        0.03856    0.4751  \n19709          134.4               NaN     0.01298        0.02062     524.0  \n\n[16180 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>perimeter_se</th>\n      <th>radius_worst</th>\n      <th>concave points_mean</th>\n      <th>smoothness_mean</th>\n      <th>area_mean</th>\n      <th>concavity_se</th>\n      <th>texture_mean</th>\n      <th>concavity_worst</th>\n      <th>smoothness_se</th>\n      <th>...</th>\n      <th>id</th>\n      <th>symmetry_mean</th>\n      <th>symmetry_worst</th>\n      <th>diagnosis</th>\n      <th>fractal_dimension_se</th>\n      <th>perimeter_mean</th>\n      <th>compactness_worst</th>\n      <th>symmetry_se</th>\n      <th>compactness_se</th>\n      <th>radius_se</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>279</td>\n      <td>1.83</td>\n      <td>NaN</td>\n      <td>0.03711</td>\n      <td>0.09516</td>\n      <td>587.4</td>\n      <td>0.01457</td>\n      <td>15.18</td>\n      <td>0.1456</td>\n      <td>0.004235</td>\n      <td>...</td>\n      <td>8911834</td>\n      <td>211.0</td>\n      <td>0.2955</td>\n      <td>B</td>\n      <td>0.001593</td>\n      <td>NaN</td>\n      <td>0.1724</td>\n      <td>0.01528</td>\n      <td>0.01541</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>307</td>\n      <td>1144.0</td>\n      <td>9699.0</td>\n      <td>0.003472</td>\n      <td>NaN</td>\n      <td>246.3</td>\n      <td>0.003681</td>\n      <td>14.4</td>\n      <td>0.01472</td>\n      <td>0.007389</td>\n      <td>...</td>\n      <td>89346</td>\n      <td>NaN</td>\n      <td>0.2991</td>\n      <td>B</td>\n      <td>0.002153</td>\n      <td>56.36</td>\n      <td>0.05232</td>\n      <td>0.02701</td>\n      <td>0.004883</td>\n      <td>0.1746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>576</td>\n      <td>2183.0</td>\n      <td>NaN</td>\n      <td>0.02278</td>\n      <td>0.09524</td>\n      <td>409.0</td>\n      <td>0.01349</td>\n      <td>18.75</td>\n      <td>NaN</td>\n      <td>0.008328</td>\n      <td>...</td>\n      <td>85759902</td>\n      <td>NaN</td>\n      <td>0.3306</td>\n      <td>B</td>\n      <td>0.002386</td>\n      <td>73.34</td>\n      <td>NaN</td>\n      <td>0.03218</td>\n      <td>0.008722</td>\n      <td>0.3249</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>350</td>\n      <td>2225.0</td>\n      <td>13.28</td>\n      <td>0.01162</td>\n      <td>0.07561</td>\n      <td>421.0</td>\n      <td>0.005949</td>\n      <td>17.07</td>\n      <td>0.03046</td>\n      <td>0.006583</td>\n      <td>...</td>\n      <td>899187</td>\n      <td>0.1671</td>\n      <td>0.2731</td>\n      <td>B</td>\n      <td>0.002668</td>\n      <td>73.7</td>\n      <td>0.06476</td>\n      <td>0.02216</td>\n      <td>0.006991</td>\n      <td>0.3534</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>120</td>\n      <td>1103.0</td>\n      <td>12.82</td>\n      <td>0.02623</td>\n      <td>0.09373</td>\n      <td>403.3</td>\n      <td>0.01514</td>\n      <td>10.82</td>\n      <td>0.2102</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>865137</td>\n      <td>0.1667</td>\n      <td>0.3016</td>\n      <td>B</td>\n      <td>0.002206</td>\n      <td>73.34</td>\n      <td>239.0</td>\n      <td>0.01344</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19703</th>\n      <td>602</td>\n      <td>2844.0</td>\n      <td>NaN</td>\n      <td>0.05613</td>\n      <td>0.1008</td>\n      <td>809.8</td>\n      <td>0.02219</td>\n      <td>21.54</td>\n      <td>0.2992</td>\n      <td>0.004877</td>\n      <td>...</td>\n      <td>86730502</td>\n      <td>216.0</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>106.2</td>\n      <td>0.3055</td>\n      <td>0.01535</td>\n      <td>0.01952</td>\n      <td>0.4332</td>\n    </tr>\n    <tr>\n      <th>19705</th>\n      <td>350</td>\n      <td>2225.0</td>\n      <td>NaN</td>\n      <td>0.01162</td>\n      <td>0.07561</td>\n      <td>421.0</td>\n      <td>0.005949</td>\n      <td>17.07</td>\n      <td>0.03046</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>899187</td>\n      <td>0.1671</td>\n      <td>0.2731</td>\n      <td>B</td>\n      <td>NaN</td>\n      <td>73.7</td>\n      <td>0.06476</td>\n      <td>0.02216</td>\n      <td>0.006991</td>\n      <td>0.3534</td>\n    </tr>\n    <tr>\n      <th>19706</th>\n      <td>442</td>\n      <td>2235.0</td>\n      <td>15.27</td>\n      <td>0.009937</td>\n      <td>NaN</td>\n      <td>585.9</td>\n      <td>0.007741</td>\n      <td>15.79</td>\n      <td>0.03517</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>90944601</td>\n      <td>0.1405</td>\n      <td>0.1859</td>\n      <td>B</td>\n      <td>0.002564</td>\n      <td>NaN</td>\n      <td>0.1071</td>\n      <td>NaN</td>\n      <td>0.01156</td>\n      <td>0.3563</td>\n    </tr>\n    <tr>\n      <th>19708</th>\n      <td>501</td>\n      <td>2974.0</td>\n      <td>16.01</td>\n      <td>0.06759</td>\n      <td>0.1162</td>\n      <td>595.9</td>\n      <td>0.03476</td>\n      <td>24.49</td>\n      <td>0.3381</td>\n      <td>0.00968</td>\n      <td>...</td>\n      <td>91504</td>\n      <td>0.2275</td>\n      <td>0.3651</td>\n      <td>M</td>\n      <td>0.006995</td>\n      <td>92.33</td>\n      <td>0.3966</td>\n      <td>0.02434</td>\n      <td>0.03856</td>\n      <td>0.4751</td>\n    </tr>\n    <tr>\n      <th>19709</th>\n      <td>233</td>\n      <td>3767.0</td>\n      <td>24.47</td>\n      <td>0.0834</td>\n      <td>0.09159</td>\n      <td>1319.0</td>\n      <td>0.03457</td>\n      <td>27.81</td>\n      <td>0.4146</td>\n      <td>0.00502</td>\n      <td>...</td>\n      <td>88206102</td>\n      <td>NaN</td>\n      <td>0.2437</td>\n      <td>M</td>\n      <td>0.002887</td>\n      <td>134.4</td>\n      <td>NaN</td>\n      <td>0.01298</td>\n      <td>0.02062</td>\n      <td>524.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>16180 rows × 33 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enconding target\n",
    "We use scikit learn LabelEncoder to encode diagnosis as follows:\n",
    "0 if diagnosis is B (Beningn) and  1 if its M (malignant)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoding = preprocessing.LabelEncoder()\n",
    "df['diagnosis'] = label_encoding.fit_transform(df['diagnosis'])\n",
    "\n",
    "## 0 es beningno y 1 es maligno\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Seting dataset column dtype as float and diagnosis as category"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "df=df.astype('float')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "df['diagnosis']=df['diagnosis'].astype('int').astype('category')\n",
    "df['index']=df['index'].astype('int')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16180 entries, 1 to 19709\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   index                    16180 non-null  int32   \n",
      " 1   perimeter_se             13640 non-null  float64 \n",
      " 2   radius_worst             13630 non-null  float64 \n",
      " 3   concave points_mean      13600 non-null  float64 \n",
      " 4   smoothness_mean          13450 non-null  float64 \n",
      " 5   area_mean                13425 non-null  float64 \n",
      " 6   concavity_se             13475 non-null  float64 \n",
      " 7   texture_mean             13565 non-null  float64 \n",
      " 8   concavity_worst          13540 non-null  float64 \n",
      " 9   smoothness_se            13610 non-null  float64 \n",
      " 10  concave points_se        13600 non-null  float64 \n",
      " 11  area_worst               13530 non-null  float64 \n",
      " 12  compactness_mean         13480 non-null  float64 \n",
      " 13  radius_mean              13495 non-null  float64 \n",
      " 14  area_se                  13475 non-null  float64 \n",
      " 15  concave points_worst     13620 non-null  float64 \n",
      " 16  fractal_dimension_worst  13615 non-null  float64 \n",
      " 17  perimeter_worst          13595 non-null  float64 \n",
      " 18  texture_se               13635 non-null  float64 \n",
      " 19  fractal_dimension_mean   13550 non-null  float64 \n",
      " 20  texture_worst            13615 non-null  float64 \n",
      " 21  smoothness_worst         13535 non-null  float64 \n",
      " 22  concavity_mean           13415 non-null  float64 \n",
      " 23  id                       14720 non-null  float64 \n",
      " 24  symmetry_mean            13485 non-null  float64 \n",
      " 25  symmetry_worst           13600 non-null  float64 \n",
      " 26  diagnosis                16180 non-null  category\n",
      " 27  fractal_dimension_se     13555 non-null  float64 \n",
      " 28  perimeter_mean           13450 non-null  float64 \n",
      " 29  compactness_worst        13725 non-null  float64 \n",
      " 30  symmetry_se              13580 non-null  float64 \n",
      " 31  compactness_se           13570 non-null  float64 \n",
      " 32  radius_se                13595 non-null  float64 \n",
      "dtypes: category(1), float64(31), int32(1)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First describe\n",
    "We can now make a first description of the raw data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "             index  perimeter_se  radius_worst  concave points_mean  \\\ncount  16180.00000  13640.000000  13630.000000         13600.000000   \nmean     328.05068   2536.409364    323.328936             2.424616   \nstd      189.47624   1738.237381   1680.786074            16.207594   \nmin        0.00000      0.771400      7.930000             0.000000   \n25%      165.75000   1482.000000     13.290000             0.020270   \n50%      326.00000   2143.000000     15.300000             0.033700   \n75%      494.00000   3168.000000     19.920000             0.077520   \nmax      656.00000   9807.000000   9981.000000           162.000000   \n\n       smoothness_mean     area_mean  concavity_se  texture_mean  \\\ncount     13450.000000  13425.000000  13475.000000  13565.000000   \nmean          3.835104    656.435978      1.147903     19.416823   \nstd          19.928257    349.181590     17.733254      4.385227   \nmin           0.052630    143.500000      0.000000      9.710000   \n25%           0.086410    420.500000      0.015140     16.330000   \n50%           0.095920    556.700000      0.026260     18.900000   \n75%           0.106100    782.700000      0.042560     21.870000   \nmax         123.000000   2501.000000    396.000000     39.280000   \n\n       concavity_worst  smoothness_se  ...  concavity_mean            id  \\\ncount     13540.000000   13610.000000  ...    13415.000000  1.472000e+04   \nmean         24.441271       0.007034  ...        7.370354  3.075898e+13   \nstd         106.068910       0.003130  ...       34.793982  1.824612e+14   \nmin           0.000000       0.001713  ...        0.000000 -8.888877e+13   \n25%           0.121100       0.005033  ...        0.029950  8.654680e+05   \n50%           0.257100       0.006307  ...        0.063870  9.079150e+05   \n75%           0.426725       0.008109  ...        0.145700  8.912944e+06   \nmax        1252.000000       0.031130  ...      313.000000  9.997654e+14   \n\n       symmetry_mean  symmetry_worst  fractal_dimension_se  perimeter_mean  \\\ncount   13485.000000    13600.000000          13555.000000    13450.000000   \nmean       16.305977       31.056838              0.010388       92.300212   \nstd        52.516520       92.196651              0.199383       24.473417   \nmin         0.116700        0.156500              0.000895       43.790000   \n25%         0.163400        0.252300              0.002217       75.490000   \n50%         0.181300        0.288400              0.003053       86.910000   \n75%         0.202700        0.331300              0.004463      104.300000   \nmax       304.000000      544.000000              6.000000      188.500000   \n\n       compactness_worst   symmetry_se  compactness_se     radius_se  \ncount       13725.000000  13580.000000    13570.000000  13595.000000  \nmean           25.303201      0.219976        0.145002     81.108863  \nstd            95.437704      2.066789        1.474177    292.899986  \nmin             0.027290      0.007882        0.002252      0.111500  \n25%             0.150800      0.015020        0.013400      0.235100  \n50%             0.229700      0.018525        0.020480      0.343800  \n75%             0.385600      0.023240        0.032470      0.590700  \nmax          1058.000000     31.000000       27.000000   2873.000000  \n\n[8 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>perimeter_se</th>\n      <th>radius_worst</th>\n      <th>concave points_mean</th>\n      <th>smoothness_mean</th>\n      <th>area_mean</th>\n      <th>concavity_se</th>\n      <th>texture_mean</th>\n      <th>concavity_worst</th>\n      <th>smoothness_se</th>\n      <th>...</th>\n      <th>concavity_mean</th>\n      <th>id</th>\n      <th>symmetry_mean</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_se</th>\n      <th>perimeter_mean</th>\n      <th>compactness_worst</th>\n      <th>symmetry_se</th>\n      <th>compactness_se</th>\n      <th>radius_se</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16180.00000</td>\n      <td>13640.000000</td>\n      <td>13630.000000</td>\n      <td>13600.000000</td>\n      <td>13450.000000</td>\n      <td>13425.000000</td>\n      <td>13475.000000</td>\n      <td>13565.000000</td>\n      <td>13540.000000</td>\n      <td>13610.000000</td>\n      <td>...</td>\n      <td>13415.000000</td>\n      <td>1.472000e+04</td>\n      <td>13485.000000</td>\n      <td>13600.000000</td>\n      <td>13555.000000</td>\n      <td>13450.000000</td>\n      <td>13725.000000</td>\n      <td>13580.000000</td>\n      <td>13570.000000</td>\n      <td>13595.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>328.05068</td>\n      <td>2536.409364</td>\n      <td>323.328936</td>\n      <td>2.424616</td>\n      <td>3.835104</td>\n      <td>656.435978</td>\n      <td>1.147903</td>\n      <td>19.416823</td>\n      <td>24.441271</td>\n      <td>0.007034</td>\n      <td>...</td>\n      <td>7.370354</td>\n      <td>3.075898e+13</td>\n      <td>16.305977</td>\n      <td>31.056838</td>\n      <td>0.010388</td>\n      <td>92.300212</td>\n      <td>25.303201</td>\n      <td>0.219976</td>\n      <td>0.145002</td>\n      <td>81.108863</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>189.47624</td>\n      <td>1738.237381</td>\n      <td>1680.786074</td>\n      <td>16.207594</td>\n      <td>19.928257</td>\n      <td>349.181590</td>\n      <td>17.733254</td>\n      <td>4.385227</td>\n      <td>106.068910</td>\n      <td>0.003130</td>\n      <td>...</td>\n      <td>34.793982</td>\n      <td>1.824612e+14</td>\n      <td>52.516520</td>\n      <td>92.196651</td>\n      <td>0.199383</td>\n      <td>24.473417</td>\n      <td>95.437704</td>\n      <td>2.066789</td>\n      <td>1.474177</td>\n      <td>292.899986</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.00000</td>\n      <td>0.771400</td>\n      <td>7.930000</td>\n      <td>0.000000</td>\n      <td>0.052630</td>\n      <td>143.500000</td>\n      <td>0.000000</td>\n      <td>9.710000</td>\n      <td>0.000000</td>\n      <td>0.001713</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-8.888877e+13</td>\n      <td>0.116700</td>\n      <td>0.156500</td>\n      <td>0.000895</td>\n      <td>43.790000</td>\n      <td>0.027290</td>\n      <td>0.007882</td>\n      <td>0.002252</td>\n      <td>0.111500</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>165.75000</td>\n      <td>1482.000000</td>\n      <td>13.290000</td>\n      <td>0.020270</td>\n      <td>0.086410</td>\n      <td>420.500000</td>\n      <td>0.015140</td>\n      <td>16.330000</td>\n      <td>0.121100</td>\n      <td>0.005033</td>\n      <td>...</td>\n      <td>0.029950</td>\n      <td>8.654680e+05</td>\n      <td>0.163400</td>\n      <td>0.252300</td>\n      <td>0.002217</td>\n      <td>75.490000</td>\n      <td>0.150800</td>\n      <td>0.015020</td>\n      <td>0.013400</td>\n      <td>0.235100</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>326.00000</td>\n      <td>2143.000000</td>\n      <td>15.300000</td>\n      <td>0.033700</td>\n      <td>0.095920</td>\n      <td>556.700000</td>\n      <td>0.026260</td>\n      <td>18.900000</td>\n      <td>0.257100</td>\n      <td>0.006307</td>\n      <td>...</td>\n      <td>0.063870</td>\n      <td>9.079150e+05</td>\n      <td>0.181300</td>\n      <td>0.288400</td>\n      <td>0.003053</td>\n      <td>86.910000</td>\n      <td>0.229700</td>\n      <td>0.018525</td>\n      <td>0.020480</td>\n      <td>0.343800</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>494.00000</td>\n      <td>3168.000000</td>\n      <td>19.920000</td>\n      <td>0.077520</td>\n      <td>0.106100</td>\n      <td>782.700000</td>\n      <td>0.042560</td>\n      <td>21.870000</td>\n      <td>0.426725</td>\n      <td>0.008109</td>\n      <td>...</td>\n      <td>0.145700</td>\n      <td>8.912944e+06</td>\n      <td>0.202700</td>\n      <td>0.331300</td>\n      <td>0.004463</td>\n      <td>104.300000</td>\n      <td>0.385600</td>\n      <td>0.023240</td>\n      <td>0.032470</td>\n      <td>0.590700</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>656.00000</td>\n      <td>9807.000000</td>\n      <td>9981.000000</td>\n      <td>162.000000</td>\n      <td>123.000000</td>\n      <td>2501.000000</td>\n      <td>396.000000</td>\n      <td>39.280000</td>\n      <td>1252.000000</td>\n      <td>0.031130</td>\n      <td>...</td>\n      <td>313.000000</td>\n      <td>9.997654e+14</td>\n      <td>304.000000</td>\n      <td>544.000000</td>\n      <td>6.000000</td>\n      <td>188.500000</td>\n      <td>1058.000000</td>\n      <td>31.000000</td>\n      <td>27.000000</td>\n      <td>2873.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16180 entries, 1 to 19709\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   index                    16180 non-null  int32   \n",
      " 1   perimeter_se             13640 non-null  float64 \n",
      " 2   radius_worst             13630 non-null  float64 \n",
      " 3   concave points_mean      13600 non-null  float64 \n",
      " 4   smoothness_mean          13450 non-null  float64 \n",
      " 5   area_mean                13425 non-null  float64 \n",
      " 6   concavity_se             13475 non-null  float64 \n",
      " 7   texture_mean             13565 non-null  float64 \n",
      " 8   concavity_worst          13540 non-null  float64 \n",
      " 9   smoothness_se            13610 non-null  float64 \n",
      " 10  concave points_se        13600 non-null  float64 \n",
      " 11  area_worst               13530 non-null  float64 \n",
      " 12  compactness_mean         13480 non-null  float64 \n",
      " 13  radius_mean              13495 non-null  float64 \n",
      " 14  area_se                  13475 non-null  float64 \n",
      " 15  concave points_worst     13620 non-null  float64 \n",
      " 16  fractal_dimension_worst  13615 non-null  float64 \n",
      " 17  perimeter_worst          13595 non-null  float64 \n",
      " 18  texture_se               13635 non-null  float64 \n",
      " 19  fractal_dimension_mean   13550 non-null  float64 \n",
      " 20  texture_worst            13615 non-null  float64 \n",
      " 21  smoothness_worst         13535 non-null  float64 \n",
      " 22  concavity_mean           13415 non-null  float64 \n",
      " 23  id                       14720 non-null  float64 \n",
      " 24  symmetry_mean            13485 non-null  float64 \n",
      " 25  symmetry_worst           13600 non-null  float64 \n",
      " 26  diagnosis                16180 non-null  category\n",
      " 27  fractal_dimension_se     13555 non-null  float64 \n",
      " 28  perimeter_mean           13450 non-null  float64 \n",
      " 29  compactness_worst        13725 non-null  float64 \n",
      " 30  symmetry_se              13580 non-null  float64 \n",
      " 31  compactness_se           13570 non-null  float64 \n",
      " 32  radius_se                13595 non-null  float64 \n",
      "dtypes: category(1), float64(31), int32(1)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving current data into a parquet file\n",
    "Saving a first dataset which contains 16180 entries with mistakes replaced for na and target column clean and only containing correctly labeled rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/interim/BreastCancer.parquet\", index = False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16180 entries, 0 to 16179\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   index                    16180 non-null  int32  \n",
      " 1   perimeter_se             13640 non-null  float64\n",
      " 2   radius_worst             13630 non-null  float64\n",
      " 3   concave points_mean      13600 non-null  float64\n",
      " 4   smoothness_mean          13450 non-null  float64\n",
      " 5   area_mean                13425 non-null  float64\n",
      " 6   concavity_se             13475 non-null  float64\n",
      " 7   texture_mean             13565 non-null  float64\n",
      " 8   concavity_worst          13540 non-null  float64\n",
      " 9   smoothness_se            13610 non-null  float64\n",
      " 10  concave points_se        13600 non-null  float64\n",
      " 11  area_worst               13530 non-null  float64\n",
      " 12  compactness_mean         13480 non-null  float64\n",
      " 13  radius_mean              13495 non-null  float64\n",
      " 14  area_se                  13475 non-null  float64\n",
      " 15  concave points_worst     13620 non-null  float64\n",
      " 16  fractal_dimension_worst  13615 non-null  float64\n",
      " 17  perimeter_worst          13595 non-null  float64\n",
      " 18  texture_se               13635 non-null  float64\n",
      " 19  fractal_dimension_mean   13550 non-null  float64\n",
      " 20  texture_worst            13615 non-null  float64\n",
      " 21  smoothness_worst         13535 non-null  float64\n",
      " 22  concavity_mean           13415 non-null  float64\n",
      " 23  id                       14720 non-null  float64\n",
      " 24  symmetry_mean            13485 non-null  float64\n",
      " 25  symmetry_worst           13600 non-null  float64\n",
      " 26  diagnosis                16180 non-null  int64  \n",
      " 27  fractal_dimension_se     13555 non-null  float64\n",
      " 28  perimeter_mean           13450 non-null  float64\n",
      " 29  compactness_worst        13725 non-null  float64\n",
      " 30  symmetry_se              13580 non-null  float64\n",
      " 31  compactness_se           13570 non-null  float64\n",
      " 32  radius_se                13595 non-null  float64\n",
      "dtypes: float64(31), int32(1), int64(1)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=pd.read_parquet(\"../data/interim/BreastCancer.parquet\", engine='pyarrow')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping unnecessary columns\n",
    "Next step is drop unnecessary columns like index and id because we dont need them for our analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "df=df.drop('id',axis=1)\n",
    "df=df.drop('index',axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deleting duplicate rows\n",
    "We first delete all duplicated rows which are exactly the same matching all their features, that's the reason for not especifying subset='col' in drop_duplicates function. After doing so, we get a dataset with 3159 rows and 31 columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(keep='first', ignore_index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3159 entries, 0 to 3235\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   perimeter_se             2651 non-null   float64\n",
      " 1   radius_worst             2649 non-null   float64\n",
      " 2   concave points_mean      2643 non-null   float64\n",
      " 3   smoothness_mean          2613 non-null   float64\n",
      " 4   area_mean                2608 non-null   float64\n",
      " 5   concavity_se             2618 non-null   float64\n",
      " 6   texture_mean             2636 non-null   float64\n",
      " 7   concavity_worst          2631 non-null   float64\n",
      " 8   smoothness_se            2645 non-null   float64\n",
      " 9   concave points_se        2643 non-null   float64\n",
      " 10  area_worst               2629 non-null   float64\n",
      " 11  compactness_mean         2619 non-null   float64\n",
      " 12  radius_mean              2622 non-null   float64\n",
      " 13  area_se                  2618 non-null   float64\n",
      " 14  concave points_worst     2647 non-null   float64\n",
      " 15  fractal_dimension_worst  2646 non-null   float64\n",
      " 16  perimeter_worst          2642 non-null   float64\n",
      " 17  texture_se               2650 non-null   float64\n",
      " 18  fractal_dimension_mean   2633 non-null   float64\n",
      " 19  texture_worst            2646 non-null   float64\n",
      " 20  smoothness_worst         2630 non-null   float64\n",
      " 21  concavity_mean           2606 non-null   float64\n",
      " 22  symmetry_mean            2620 non-null   float64\n",
      " 23  symmetry_worst           2643 non-null   float64\n",
      " 24  diagnosis                3159 non-null   int64  \n",
      " 25  fractal_dimension_se     2634 non-null   float64\n",
      " 26  perimeter_mean           2613 non-null   float64\n",
      " 27  compactness_worst        2668 non-null   float64\n",
      " 28  symmetry_se              2639 non-null   float64\n",
      " 29  compactness_se           2637 non-null   float64\n",
      " 30  radius_se                2642 non-null   float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 789.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Saving a dataset without duplicates and including nas, this is done in order to use this dataset in other possible experiments (breastcancerdeduplicated.parquet).**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/interim/BreastCancerdeduplicated.parquet\", index = False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data set for the first experiment.\n",
    "For our first experiment we'll use a dataset with no NaN's. We delete rows with na features, it means we only use examples with all valid and filled features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "df['diagnosis']=df['diagnosis'].astype('category') ##seting diagnosis column as category"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 569 entries, 3 to 3234\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   perimeter_se             569 non-null    float64 \n",
      " 1   radius_worst             569 non-null    float64 \n",
      " 2   concave points_mean      569 non-null    float64 \n",
      " 3   smoothness_mean          569 non-null    float64 \n",
      " 4   area_mean                569 non-null    float64 \n",
      " 5   concavity_se             569 non-null    float64 \n",
      " 6   texture_mean             569 non-null    float64 \n",
      " 7   concavity_worst          569 non-null    float64 \n",
      " 8   smoothness_se            569 non-null    float64 \n",
      " 9   concave points_se        569 non-null    float64 \n",
      " 10  area_worst               569 non-null    float64 \n",
      " 11  compactness_mean         569 non-null    float64 \n",
      " 12  radius_mean              569 non-null    float64 \n",
      " 13  area_se                  569 non-null    float64 \n",
      " 14  concave points_worst     569 non-null    float64 \n",
      " 15  fractal_dimension_worst  569 non-null    float64 \n",
      " 16  perimeter_worst          569 non-null    float64 \n",
      " 17  texture_se               569 non-null    float64 \n",
      " 18  fractal_dimension_mean   569 non-null    float64 \n",
      " 19  texture_worst            569 non-null    float64 \n",
      " 20  smoothness_worst         569 non-null    float64 \n",
      " 21  concavity_mean           569 non-null    float64 \n",
      " 22  symmetry_mean            569 non-null    float64 \n",
      " 23  symmetry_worst           569 non-null    float64 \n",
      " 24  diagnosis                569 non-null    category\n",
      " 25  fractal_dimension_se     569 non-null    float64 \n",
      " 26  perimeter_mean           569 non-null    float64 \n",
      " 27  compactness_worst        569 non-null    float64 \n",
      " 28  symmetry_se              569 non-null    float64 \n",
      " 29  compactness_se           569 non-null    float64 \n",
      " 30  radius_se                569 non-null    float64 \n",
      "dtypes: category(1), float64(30)\n",
      "memory usage: 138.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() ##Datatypes are now in their correct dtypes (float64 for numeric values and category for target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## After cleaning the data we get a dataset with no nas nor mistakes. The resulting dataset contains 569 examples (rows), 30 features and 1 target (diagnosis). We'll use this dataset (Breastclean1) for the first experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/interim/Breastclean1.parquet\", index = False) ##saving dataset (569 examples 30 features and 1 target)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partial Results\n",
    "**Initial raw data (dataset name: BreastCancerDS.csv)**\n",
    "- 19719 rows, 35 Columns , memory usage: 5.4+ MB\n",
    "\n",
    "\n",
    "**After cleaning process without duplicates ,including nas (dataset name: breastcancerdeduplicated.parquet) :**\n",
    "- 3159 rows , 31 Columns , memory usage: 789.8 KB\n",
    "\n",
    "\n",
    "\n",
    "**Clean dataset after dropping nas and duplicates (dataset name: Breastclean1.parquet):**\n",
    "- 569 rows, 31 columns, memory usage :138.5 KB\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
